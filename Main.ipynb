{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### !!! DO ONLY ONCE !!! ####\n",
    "# WE IMPORT THE DATA INTO OUR LOCAL ECOSYSTEM\n",
    "##### !!! DO ONLY ONCE !!! ####\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "print('Beginning file download with urllib2...')\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'  \n",
    "urllib.request.urlretrieve(url, '/Users/Juan/A_DataScience_Project/datasets/cleveland.data')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE READ THE DATA FROM OUR LOCAL ECOSYSTEM\n",
    "filepath = '/Users/Juan/A_DataScience_Project/datasets/'\n",
    "filename = 'cleveland.data'\n",
    "f=open(filepath + filename,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#WE DEFINE A FUNCTION TO CONVERT THE TEXT EXTRACTED (.data file) TO A PYTHON OBJECT\n",
    "def create_object_from_string(data):\n",
    "    new_val = \"\"\n",
    "    new_row = []\n",
    "    new_object = []\n",
    "    skip_row = False\n",
    "    for elem in data:\n",
    "        if elem != \",\" and elem != \"\\n\":\n",
    "            #We append characters until we have a whole value (indicated by a comma or a new-line)\n",
    "            new_val += elem\n",
    "            if elem == \"?\":\n",
    "                skip_row = True\n",
    "        elif elem == \",\":\n",
    "            # We ommit the rows that have an unkown value < \"?\" >\n",
    "            if skip_row == True:\n",
    "                new_val = \"\"\n",
    "                continue\n",
    "            \n",
    "            # We append the new value to the row\n",
    "            new_row.append( float(new_val) )\n",
    "            new_val = \"\"\n",
    "        elif elem == \"\\n\":\n",
    "            # We ommit the rows that have an unkown value < \"?\" >\n",
    "            if skip_row == True:\n",
    "                new_row = []\n",
    "                skip_row = False\n",
    "                continue\n",
    "            \n",
    "            # We append the new value to the row\n",
    "            new_row.append( float(new_val) )\n",
    "            new_val = \"\"\n",
    "            \n",
    "            # We append the new row to the object\n",
    "            new_object.append(new_row)\n",
    "            new_row = []\n",
    "\n",
    "    return new_object\n",
    "\n",
    "\n",
    "\n",
    "#WE DEFINE A FUNCTION TO EXTRACT THE LAST ELEMENT OF EACH DATASET ROW  -->  Input/Output SPLIT\n",
    "def separate_input_from_output(obj):\n",
    "    \n",
    "    _, n_values = np.shape(obj)\n",
    "    \n",
    "    n_inputs = n_values-1\n",
    "    \n",
    "    input_object = []\n",
    "    output_object = []\n",
    "    for row in obj:\n",
    "        input_row = row[0:n_inputs]\n",
    "        output_row = row[n_values-1]\n",
    "        \n",
    "        input_object.append(input_row)\n",
    "        output_object.append(output_row)\n",
    "    \n",
    "    return input_object, output_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- DATA EXTRACTED ---------\n",
      "\n",
      "NUMBER OF CASES: 297\n",
      "NUMBER OF ATTRIBUTES: 14\n",
      "FIRST ROW:  [63.0, 1.0, 1.0, 145.0, 233.0, 1.0, 2.0, 150.0, 0.0, 2.3, 3.0, 0.0, 6.0, 0.0]\n",
      "LAST ROW:  [57.0, 0.0, 2.0, 130.0, 236.0, 0.0, 2.0, 174.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#WE HAVE A LOOK INTO THE DATA DOWNLOADED\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "dataset_string = f.read()\n",
    "dataset = create_object_from_string(dataset_string)\n",
    "\n",
    "n_cases, n_attributes = np.shape(dataset)\n",
    "\n",
    "print( \"------- DATA EXTRACTED ---------\\n\" )\n",
    "print( \"NUMBER OF CASES:\", n_cases )\n",
    "print( \"NUMBER OF ATTRIBUTES:\", n_attributes )\n",
    "print( \"FIRST ROW: \", dataset[0] )\n",
    "print( \"LAST ROW: \", dataset[ n_cases-1 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- DATA SEPARATED ---------\n",
      "\n",
      "1st ROW INPUT:  [63.0, 1.0, 1.0, 145.0, 233.0, 1.0, 2.0, 150.0, 0.0, 2.3, 3.0, 0.0, 6.0]\n",
      "1st ROW OUTPUT:  0.0\n",
      "Last ROW INPUT:  [57.0, 0.0, 2.0, 130.0, 236.0, 0.0, 2.0, 174.0, 0.0, 0.0, 2.0, 1.0, 3.0]\n",
      "Last ROW OUTPUT:  1.0\n"
     ]
    }
   ],
   "source": [
    "#WE SPLIT THE DATA INTO INPUT & OUTPUT SETS\n",
    "X,Y = separate_input_from_output(dataset)\n",
    "print( \"------- DATA SEPARATED ---------\\n\" )\n",
    "print( \"1st ROW INPUT: \", X[0] )\n",
    "print( \"1st ROW OUTPUT: \", Y[0] )\n",
    "print( \"Last ROW INPUT: \", X[ n_cases-1 ] )\n",
    "print( \"Last ROW OUTPUT: \", Y[ n_cases-1 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_Classifier_Class:\n",
    "    def __init__(self, layers_vec, X, Y, training_vs_test_percentage = 0.7):\n",
    "        \n",
    "        #WE ASSERT NETWORK CONFIGURATION IS CORRECT\n",
    "        assert len(layers_vec) > 2, \"AT LEAST 2 NUMBERS HAVE TO BE PASSED: INPUT & OUTPUT SIZES HAVE TO BE PROVIDED\"\n",
    "        for elem in layers_vec:\n",
    "            assert elem > 1, \"INPUT, OUTPUT, & MIDDLE-LAYERS MUST HAVE A SIZE GREATER THAN 1\"\n",
    "        \n",
    "        self.n_layers = len(layers_vec)\n",
    "        self.n_inputs = layers_vec[0]\n",
    "        self.n_outputs = layers_vec[n_layers-1]\n",
    "        \n",
    "        #WE ASSERT INPUT CONFIGURATION IS CORRECT\n",
    "        assert np.shape(X)[1] == self.n_inputs, \"NUMBER OF INPUTS PASSED MUST BE EQUAL TO NUMBER OF ATTRIBUTES ON INPUT MATRIX < X >\"\n",
    "        n_samples = np.shape(X)[0]\n",
    "        assert n_samples > 100, \"100 INPUT CASES NEED TO BE RECEIVED AT LEAST\"\n",
    "        \n",
    "        #WE ASSERT OUTPUT CONFIGURATION IS CORRECT\n",
    "        assert np.shape(Y)[1], \"OUTPUT MUST BE GIVEN AS AN INTEGER NUMBER\"\n",
    "        for elem in Y:\n",
    "            assert elem >= 0 and elem <= self.n_outputs, \"AT LEAST ONE OUTPUT VALUE IS OUT OF THE RANGE PROVIDED\"\n",
    "        \n",
    "        #WE ASSERT INPUT-OUTPUT CONFIGURATION MATCHES\n",
    "        assert np.shape(Y)[0] == n_samples, \"NUMBER OF INPUT AND OUTPUT CASES NEED TO MATCH\"\n",
    "        \n",
    "        #WE ASSERT THE TRAINING/TEST RELATION IS CORRECT\n",
    "        assert training_vs_test_percentage > 0 and training_vs_test_percentage < 1, \"TRAINING PERCENTAGE HAS TO BE IN THE [0-1] RANGE\"\n",
    "        \n",
    "        \n",
    "        n_train_samples = n_samples*training_vs_test_percentage\n",
    "        \n",
    "        self.X_train = X[0:n_train_samples]\n",
    "        self.Y_train = Y[0:n_train_samples]\n",
    "        \n",
    "        self.X_test = X[n_train_samples:n_samples]\n",
    "        self.Y_test = Y[n_train_samples:n_samples]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #def create_layer(self, ):\n",
    "    #def create_network(self, ):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = [2,3,6,2]\n",
    "for elem in j:\n",
    "    assert elem > 1, \"HELLO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
